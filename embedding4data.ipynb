{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "embedding4data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPzZdgaxMmxD3weZvh/meTT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deb-kit2/coHereHack/blob/main/embedding4data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lD4WzXJI7v3G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abb37c95-fff7-44a0-ea55-87951163f1e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cohere in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from cohere) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->cohere) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->cohere) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->cohere) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->cohere) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.64.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.21.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.13.1+cu113)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.12.1+cu113)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.8.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.7.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.1.97)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.1.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.12.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence_transformers) (3.8.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install cohere\n",
        "! pip install -U sentence_transformers\n",
        "# for cosine similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "xxyNndM5ywmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import copy\n",
        "import random\n",
        "\n",
        "import cohere\n",
        "from sentence_transformers import util"
      ],
      "metadata": {
        "id": "poAzvBhOyxmq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Data"
      ],
      "metadata": {
        "id": "svoYVd_ayZqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"data/\"\n",
        "\n",
        "# asset\n",
        "dataorig = []\n",
        "datasimple = []\n",
        "\n",
        "fp = open(path + \"assetValid.txt\", \"r\", encoding = \"utf-8\")\n",
        "for line in fp :\n",
        "    dataorig.append(line)\n",
        "fp.close()\n",
        "\n",
        "temp = copy.deepcopy(dataorig)\n",
        "for i in range(9) :\n",
        "    dataorig.extend(temp)\n",
        "\n",
        "for i in range(10) :\n",
        "    fp = open(path + \"assetValid_\" + str(i) + \".txt\", \"r\", encoding = \"utf-8\")\n",
        "    for line in fp :\n",
        "        datasimple.append(line)\n",
        "    fp.close()\n",
        "\n",
        "# medText\n",
        "normal = []\n",
        "simple = []\n",
        "\n",
        "fp = open(path + \"meddecxt_data.txt\", \"r\", encoding = \"utf-8\")\n",
        "for line in fp :\n",
        "    t = line.split(\"--separator--\")\n",
        "    \n",
        "    for tc in t :\n",
        "        x = tc.split(\"--EOI--\")\n",
        "\n",
        "        y = x[1].strip()\n",
        "        x = x[0].split(\"--simplificataion--\")[-1].strip()\n",
        "\n",
        "        normal.append(x)\n",
        "        simple.append(y)\n",
        "\n",
        "fp.close()\n",
        "\n",
        "dataorig.extend(normal)\n",
        "datasimple.extend(simple)\n",
        "\n",
        "## ls\n",
        "lsOrig = []\n",
        "lsSimple = []\n",
        "\n",
        "fp = open(path + \"ls_original.txt\", \"r\", encoding = \"utf-8\")\n",
        "for line in fp :\n",
        "    lsOrig.append(line)\n",
        "fp.close()\n",
        "\n",
        "fp = open(path + \"ls_simplified.txt\", \"r\", encoding = \"utf-8\")\n",
        "for line in fp :\n",
        "    lsSimple.append(line)\n",
        "fp.close()\n",
        "\n",
        "dataorig.extend(lsOrig)\n",
        "datasimple.extend(lsSimple)\n",
        "\n",
        "## ss\n",
        "ssOrig = []\n",
        "ssSimple = []\n",
        "\n",
        "fp = open(path + \"ss_original.txt\", \"r\", encoding = \"utf-8\")\n",
        "for line in fp :\n",
        "    ssOrig.append(line)\n",
        "fp.close()\n",
        "\n",
        "temp = copy.deepcopy(ssOrig)\n",
        "ssOrig.extend(temp)\n",
        "\n",
        "fp = open(path + \"ss_ls_simplified.txt\", \"r\", encoding = \"utf-8\")\n",
        "for line in fp :\n",
        "    ssSimple.append(line)\n",
        "fp.close()\n",
        "\n",
        "fp = open(path + \"ss_simplified.txt\", \"r\", encoding = \"utf-8\")\n",
        "for line in fp :\n",
        "    ssSimple.append(line)\n",
        "fp.close()\n",
        "\n",
        "dataorig.extend(ssOrig)\n",
        "datasimple.extend(ssSimple)\n",
        "\n",
        "# shuffle and merge\n",
        "random.Random(42).shuffle(dataorig)\n",
        "random.Random(42).shuffle(datasimple)"
      ],
      "metadata": {
        "id": "V2r9JQgsYSr5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataorig), len(datasimple))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InaLANgSz69-",
        "outputId": "85e6405d-bb1a-4c88-d8e8-334a791fcedf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28890 28890\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Embeddings"
      ],
      "metadata": {
        "id": "uKo0fTwYyikE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "co = cohere.Client('bCLcz9DdEUqlFHWflXJG25sofkawR3PraHbBsOKY')\n",
        "\n",
        "response = co.embed(model = 'small', texts = dataorig)\n",
        "dataOrig_embeddings = response.embeddings\n",
        "\n",
        "response = co.embed(model = 'small', texts = datasimple)\n",
        "dataSimple_embeddings = response.embeddings"
      ],
      "metadata": {
        "id": "Z0-2plQTYVRu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtering data, based on similarity with the reference text"
      ],
      "metadata": {
        "id": "CNILW_NRyndb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 6921\n",
        "fp = open(\"mergedAssetMedPA.txt\", \"w\", encoding = \"utf-8\")\n",
        "\n",
        "for i in range(len(dataOrig_embeddings)) :\n",
        "    similarity = float(util.pytorch_cos_sim(dataOrig_embeddings[i], dataSimple_embeddings[i]))\n",
        "\n",
        "    if similarity > 0.92 or similarity < 0.30 :\n",
        "        continue\n",
        "\n",
        "    count += 1\n",
        "    text = \"Simplify the below text:\\n\" + \"Complex input: \" + dataorig[i].strip() + \"\\nSimplified output: \" + datasimple[i].strip() + \"\\n--separator--\\n\"\n",
        "    fp.write(text)\n",
        "\n",
        "fp.close()\n",
        "\n",
        "print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkUVWF9OYgN9",
        "outputId": "efe786c7-bd2d-4bcc-b369-03ff733a0b64"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6921\n"
          ]
        }
      ]
    }
  ]
}